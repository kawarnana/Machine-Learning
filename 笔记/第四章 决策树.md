## 1. 基本流程
### 1.1 决策树(Decision tree)
       决策树(decision tree)是一种基本的分类与回归方法.   
       在分类问题中，表示基于属性(或特征)对样本(或实例)进行分类的过程。
       
决策树学习的目的：为了产生一颗泛化能力强，即处理未见示例能力强的决策树。

决策树由结点(node)和有向边(directed edge)组成。   
      结点有：内部结点(internal node)---表示一个属性(或特征)，叶节点(leaf node)---表示一种决策结果(或类)
      
### 1.2 决策树与 if-then路径
决策树可看成是一个if-then路径的集合，**决策树的路径有一个重要的性质：互斥并且完备。** ，即每一个样本都被一条路径所覆盖，而且只被一条路径所覆盖。
![Alt text](https://github.com/kawarnana/Machine-Learning/blob/master/pictures/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95.png)
    
    在决策树基本算法中，有三种情况会导致递归返回：
    case1: 当前节点包含的样本全属于同一类别，无需划分。   
    case2: 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分。
    case3: 当前节点包含的样本集合为空，不能划分。
    
## 2. 划分选择

## 3. 剪枝处理
## 4. 连续值与缺失值
## 5. 多变量决策树
